<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>Towards efficient models for real-time deep noise suppression - Sidharth Arya</title><meta name="Description" content="Sidharth Arya&#39;s Personal Blog"><meta property="og:title" content="Towards efficient models for real-time deep noise suppression" />
<meta property="og:description" content="Notes ABSTRACT  Reasonably small recurrent and Convolutional Neural Networks   architectures on large dataset.
 Reverberation was also considered Evaluated Convolutional Neural Networks architectures Trade off between computational complexity and the achievable speech quality  INTRODUCTION Models  Recurrent Neural Networks - efficient temporal modeling capabilities but hits performance saturation Convolutional Recurrent Networks and Convolutional Neural Networks raised performance but enormously large architectures NOTE: (with ref: (Luo and Mesgarani 2019 ) ) time domain networks can in THEORY produce better results than frequency domain networks but not yet realized." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://sidhartharya.github.io/braindump/20210726230715-towards_efficient_models_for_real_time_deep_noise_suppression/" /><meta property="og:image" content="https://sidhartharya.github.io/logo.png"/><meta property="article:section" content="braindump" />



<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://sidhartharya.github.io/logo.png"/>

<meta name="twitter:title" content="Towards efficient models for real-time deep noise suppression"/>
<meta name="twitter:description" content="Notes ABSTRACT  Reasonably small recurrent and Convolutional Neural Networks   architectures on large dataset.
 Reverberation was also considered Evaluated Convolutional Neural Networks architectures Trade off between computational complexity and the achievable speech quality  INTRODUCTION Models  Recurrent Neural Networks - efficient temporal modeling capabilities but hits performance saturation Convolutional Recurrent Networks and Convolutional Neural Networks raised performance but enormously large architectures NOTE: (with ref: (Luo and Mesgarani 2019 ) ) time domain networks can in THEORY produce better results than frequency domain networks but not yet realized."/>
<meta name="application-name" content="Sidharth Arya">
<meta name="apple-mobile-web-app-title" content="Sidharth Arya"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://sidhartharya.github.io/braindump/20210726230715-towards_efficient_models_for_real_time_deep_noise_suppression/" /><link rel="prev" href="https://sidhartharya.github.io/braindump/20220103125346-transformers/" /><link rel="next" href="https://sidhartharya.github.io/braindump/20210727104426-threading/" /><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css"><meta name="google-site-verification" content="1kiaMrbws-PX7eB3xh8iS1DFBTwNFcpy2xmaFXkcLrk" /><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Towards efficient models for real-time deep noise suppression",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/sidhartharya.github.io\/braindump\/20210726230715-towards_efficient_models_for_real_time_deep_noise_suppression\/"
        },"image": ["https:\/\/sidhartharya.github.io\/images\/Apple-Devices-Preview.png"],"genre": "braindump","wordcount":  954 ,
        "url": "https:\/\/sidhartharya.github.io\/braindump\/20210726230715-towards_efficient_models_for_real_time_deep_noise_suppression\/","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
            "@type": "Organization",
            "name": "xxxx","logo": "https:\/\/sidhartharya.github.io\/images\/avatar.png"},
            "author": {
                "@type": "Person",
                "name": .Site.Author.name
            },
        "description": ""
    }
    </script><script data-ad-client="ca-pub-4788308835707864" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Sidharth Arya">Sidharth Arya</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><a class="menu-item" href="/braindump/index.html"> Braindump </a><a class="menu-item" href="https://github.com/SidharthArya" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i>  </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Sidharth Arya">Sidharth Arya</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a class="menu-item" href="/braindump/index.html" title="">Braindump</a><a class="menu-item" href="https://github.com/SidharthArya" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i></a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">Towards efficient models for real-time deep noise suppression</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="sidhartharya.me" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>Sidharth Arya</a>
</span></div>
            <div class="post-meta-line">
                <i class="fas fa-pencil-alt fa-fw"></i>&nbsp;954 words&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;5 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#notes">Notes</a>
      <ul>
        <li><a href="#abstract">ABSTRACT</a></li>
        <li><a href="#introduction">INTRODUCTION</a>
          <ul>
            <li><a href="#models">Models</a></li>
            <li><a href="#goal-homearyadownloadspapers210109249pdf-annot-1-3">Goal {#/home/arya/Downloads/Papers/2101.09249.pdf-annot-1-3}</a></li>
          </ul>
        </li>
        <li><a href="#enhancement-system-and-training-objective">ENHANCEMENT SYSTEM AND TRAINING OBJECTIVE</a></li>
        <li><a href="#network-architectures">NETWORK ARCHITECTURES</a>
          <ul>
            <li><a href="#nsnet2">NSnet2</a></li>
            <li><a href="#cruse">CRUSE</a></li>
          </ul>
        </li>
        <li><a href="#experimental-setup">EXPERIMENTAL SETUP</a>
          <ul>
            <li><a href="#dataset">Dataset</a></li>
            <li><a href="#algorithmic-parameters">Algorithmic parameters</a></li>
          </ul>
        </li>
        <li><a href="#results">RESULTS</a></li>
        <li><a href="#conclusions">CONCLUSIONS</a></li>
      </ul>
    </li>
    <li><a href="#bibliography">Bibliography</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h2 id="notes">Notes</h2>
<h3 id="abstract">ABSTRACT</h3>
<ul>
<li>Reasonably small recurrent and <a href="/braindump/20210721174649-neural_networks/#7947dad5-fb28-479e-9167-ebeb092e504f" rel="">Convolutional Neural Networks</a>
</li>
</ul>
<p>architectures on large dataset.</p>
<ul>
<li>Reverberation was also considered</li>
<li>Evaluated <a href="/braindump/20210721174649-neural_networks/#7947dad5-fb28-479e-9167-ebeb092e504f" rel="">Convolutional Neural Networks</a>
 architectures</li>
<li>Trade off between computational complexity and the achievable
speech quality</li>
</ul>
<h3 id="introduction">INTRODUCTION</h3>
<h4 id="models">Models</h4>
<ul>
<li><a href="/braindump/20210721174649-neural_networks/#5d677af3-e64f-4b0d-b854-84fdd6592d71" rel="">Recurrent Neural Networks</a>
 - efficient temporal modeling
capabilities but hits performance saturation</li>
<li><a href="/braindump/20210721174649-neural_networks/#c161d52d-3c17-4f1f-af75-f11dc9a4cdd0" rel="">Convolutional Recurrent Networks</a>
 and <a href="/braindump/20210721174649-neural_networks/#7947dad5-fb28-479e-9167-ebeb092e504f" rel="">Convolutional Neural Networks</a>

raised performance but enormously large architectures
NOTE: (with ref: (<a href="#org-target--citeproc-bib-item-1" rel="">Luo and Mesgarani 2019</a>
) ) time domain networks can
in <strong>THEORY</strong> produce better results than frequency domain networks
but not yet realized.</li>
</ul>
<h4 id="goal-homearyadownloadspapers210109249pdf-annot-1-3">Goal {#/home/arya/Downloads/Papers/2101.09249.pdf-annot-1-3}</h4>
<p>which network parts can be scaled, removed, or replaced by more efficient modules, at which gains in complexity and which loss in quality. Specifically, we investigate the influence of RNN size, type, and the use of disconnected parallel RNNs. For CRNs with a symmetric convolutional encoder/decoder structure, we investigate the convolution layers, spectral vs. spectro-temporal convolutions, and skip connections. As a result, we propose an efficient CRN structure with around 4-5 times less computational operations with similar quality than previously proposed CRNs.</p>
<h3 id="enhancement-system-and-training-objective">ENHANCEMENT SYSTEM AND TRAINING OBJECTIVE</h3>
<ul>
<li>
<p>Spectral Suppression based enhancement systems - robust
generalization, logical interpretation and control, and easier
integration with existing speech processing algorithms.</p>
</li>
<li>
<p>Input Features are <strong>log power spectra</strong></p>
</li>
<li>
<p>Output is a real-valued, time varying suppression gain per time
frequency bin</p>
</li>
<li>
<p>To compute a single frame, the network requires only the features
of the current frame, or when using causal convolution, also
several past frames. So latency depends only on the STFT window
size.</p>
</li>
<li>
<p>STFT consistency is enforced by propagating FD output through
reconstruction and another STFT to compute a FD loss.</p>
<figure><img src="Notes/2021-07-06_11-59-50_2021-07-06-115330_757x265_scrot.png"/>
</figure>

</li>
<li>
<p>Both Predicted and target signals are <strong>normalized</strong> by the active
target utterance level, to enure balanced optimization for signal
level dependent losses.</p>
</li>
<li>
<p>MSE is used, blending the magnitude only with a phase aware term,
which is found to be superior to other losses for reverberant
speech enhancement.
Loss function is given by
\[L = (1-\lambda)\Sigma_{k,n}||S|^c - |\hat S|^c|^2 + \lambda
\Sigma_{k,n}||S|^c e^{j\psi s} - |\hat S|^c e^{j \psi s}|^2\]
where c = 0.3 is a compression factor, λ = 0.3 is a
weighting between complex and magnitude based loss, and omitted
the dependency of the target speech spectral bins S(k,n) on the
frequency and time indices k, n for brevity.</p>
</li>
<li>
<p>The networks are trained in batches of 10 sequences of 10 s
length using the AdamW optimizer, learning rate of \[8 *
10^{-5}\] and weight decay of 0.1.</p>
</li>
<li>
<p>The best model is picked based on the validation metric using a
heuristic optimization criterion using perceptual evaluation of
speech quality, scale invariant signal to noise ration and
cepstral distance
\[ Q = PESQ + 0.2 * siSRD - CD\]</p>
</li>
</ul>
<h3 id="network-architectures">NETWORK ARCHITECTURES</h3>
<h4 id="nsnet2">NSnet2</h4>
<ul>
<li>Consists only of fully connected and gated recurrent unit layers in</li>
</ul>
<p>the form
FC-GRU-GRU-FC-FC-FC.</p>
<ul>
<li>All FC layers are followed by ReLU activation</li>
<li>Except the last layer has sigmoid activations to predict
constrained suppression</li>
<li>The standard layer dimensions are 400 for GRUs and 600 for FC
layers i/e/ 400-400-400-600-600-K</li>
<li>Also investigated different configurations</li>
<li>The input and output dimensions are the number of frequency bins.</li>
</ul>
<h4 id="cruse">CRUSE</h4>
<ul>
<li>CRN U-Net structure</li>
<li>Convolutional Recurrent U-net for Speech Enhancement (CRUSE)</li>
</ul>
<figure><img src="Notes/2021-07-06_15-10-38_2021-07-06-150859_837x528_scrot.png"/>
</figure>

<ul>
<li>L symmetric convolutional and deconvolutional encoder and
decoder layers with kernels of size (2,3) in time an frequency
dimensions. Convolution kernels move with a stride of (1,2)
i.e. downsample the features along the frequency axis
efficiently while the number of channels C<sub>l</sub> for layer
{1,&hellip;,L} increase per encoder layer, and decrease mirrored in
the decoder. In this work the input and output channels C<sub>in</sub>
= C<sub>out</sub> = 1 but they can be extended to e.g. take complex
values or multiple features as multiple
channels. Convolutional layers are followed by leaky ReLU
activations while the last layer uses sigmoid. Between encoder
and decoder sits a recurrent layer, which is fed with all
features flattened along channels.</li>
<li>Using 1 GRU layer over 2 LSTM layers at this stage leads to
<strong>little performance loss</strong>, but <strong>huge computational savings</strong></li>
<li>GRU saves 25% complexity compared to an LSTM layer.</li>
</ul>
<p><strong>Further Modifications</strong></p>
<ul>
<li>
<p>Parallel RNN grouping
Performance of both CRUSE and NSNet2 directly scales with
bottleneck size i.e. the width R of the central RNN
layers. However, the complexity of RNN layers scales with R^2
making wide RNNs computational unattractive. There for RNNs
are grouped into P disconnected parallel RNNs, still yielding
the same forward information flow.</p>
<ul>
<li>Possible parallel execution of disconnected RNNs.</li>
</ul>
</li>
<li>
<p>Skip Connections
Use skip connection by adding rather than concatenating.</p>
<ul>
<li>More effective</li>
<li>Minor Performance degradation</li>
</ul>
<p>Also added a trainable channel wise scaling and bias in the
add skip connection implemented as convolutions</p>
</li>
</ul>
<figure><img src="Notes/2021-07-06_15-53-22_2021-07-06-155308_825x311_scrot.png"/>
</figure>

<h3 id="experimental-setup">EXPERIMENTAL SETUP</h3>
<h4 id="dataset">Dataset</h4>
<ul>
<li>large scale synthetic training set and test on real recordings</li>
<li>544 hours of high mean opinion score</li>
<li>Most data open sourced
<ul>
<li>T_{60] &gt; 0.22s and C<sub>50</sub> &lt; 18 dB implies reverberation</li>
</ul>
</li>
<li><strong>Data Generation Pipeline</strong></li>
</ul>
<figure><img src="Notes/2021-07-06_16-13-50_2021-07-06-161315_763x470_scrot.png"/>
</figure>

<ul>
<li></li>
</ul>
<h4 id="algorithmic-parameters">Algorithmic parameters</h4>
<ul>
<li>16kHz sampling frequency</li>
<li>STFT with 50% overlapping squareroot-Hann windows of 20ms length</li>
<li>FFT size of 320 points</li>
<li>Input is 161 dimensional log power spectra</li>
<li>NSnet2-R where R denotes the number of GRU node per layer</li>
<li>parameterize CRUSE with different encoder decoder sizes,
starting alway with C_1 = 16 channels, and doubling the channels
each layer.</li>
<li>CRUSE L-C_L - NxRNNP, where L are the number of E-D layers, the
last encoder layer filters C_L can vary to scale the RNN layer
width, N are the number of RNN layers and P are the number of
parallel RNNs.</li>
<li>Convolution kernels are always (2,3), unless denoted explicitly
as 1D convolutions with (1,3) kernels operating only across
frequency.</li>
</ul>
<h3 id="results">RESULTS</h3>
<h3 id="conclusions">CONCLUSIONS</h3>
<ul>
<li>Speech Quality is a function of network size, especially
depending on the recurrent layer width</li>
</ul>
<h2 id="bibliography">Bibliography</h2>
<p><span class="org-target" id="org-target--citeproc-bib-item-1"></span>Luo, Yi, and Nima Mesgarani. 2019. “Conv-Tasnet: Surpassing Ideal Time-Frequency Magnitude Masking for Speech Separation.” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em> 27 (8):1256–66. <a href="https://doi.org/10.1109/taslp.2019.2915167" target="_blank" rel="noopener noreffer">https://doi.org/10.1109/taslp.2019.2915167</a>
.</p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 0001-01-01</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/braindump/20210726230715-towards_efficient_models_for_real_time_deep_noise_suppression/index.md" target="_blank">Read Markdown</a>
                        </span></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://sidhartharya.github.io/braindump/20210726230715-towards_efficient_models_for_real_time_deep_noise_suppression/" data-title="Towards efficient models for real-time deep noise suppression" data-via="SidharthArya_"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://sidhartharya.github.io/braindump/20210726230715-towards_efficient_models_for_real_time_deep_noise_suppression/"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="Share on Linkedin" data-sharer="linkedin" data-url="https://sidhartharya.github.io/braindump/20210726230715-towards_efficient_models_for_real_time_deep_noise_suppression/"><i class="fab fa-linkedin fa-fw"></i></a><a href="javascript:void(0);" title="Share on WhatsApp" data-sharer="whatsapp" data-url="https://sidhartharya.github.io/braindump/20210726230715-towards_efficient_models_for_real_time_deep_noise_suppression/" data-title="Towards efficient models for real-time deep noise suppression" data-web><i class="fab fa-whatsapp fa-fw"></i></a><a href="javascript:void(0);" title="Share on Hacker News" data-sharer="hackernews" data-url="https://sidhartharya.github.io/braindump/20210726230715-towards_efficient_models_for_real_time_deep_noise_suppression/" data-title="Towards efficient models for real-time deep noise suppression"><i class="fab fa-hacker-news fa-fw"></i></a><a href="javascript:void(0);" title="Share on Reddit" data-sharer="reddit" data-url="https://sidhartharya.github.io/braindump/20210726230715-towards_efficient_models_for_real_time_deep_noise_suppression/"><i class="fab fa-reddit fa-fw"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://sidhartharya.github.io/braindump/20210726230715-towards_efficient_models_for_real_time_deep_noise_suppression/" data-title="Towards efficient models for real-time deep noise suppression"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@2.14.0/icons/line.svg"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://sidhartharya.github.io/braindump/20210726230715-towards_efficient_models_for_real_time_deep_noise_suppression/" data-title="Towards efficient models for real-time deep noise suppression"><i class="fab fa-weibo fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/braindump/20220103125346-transformers/" class="prev" rel="prev" title="Transformers"><i class="fas fa-angle-left fa-fw"></i>Transformers</a>
            <a href="/braindump/20210727104426-threading/" class="next" rel="next" title="Threading">Threading<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id="comments"><div id="disqus_thread" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://disqus.com/?ref_noscript">Disqus</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Thank you for supporting me.<i class='far fa-heart fa-fw'></i></div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2021 - 2022</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="sidhartharya.me" target="_blank">Sidharth Arya</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.2.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.css"><script type="text/javascript" src="https://sidhartharya-me.disqus.com/embed.js" defer></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.37.1/dist/autocomplete.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lunr@2.3.8/lunr.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.2.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.2.0/dist/js/lightgallery.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.2.0/dist/lg-zoom.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.4.0/sharer.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{},"lightGallery":{"actualSize":false,"exThumbImage":"data-thumbnail","hideBarsDelay":2000,"selector":".lightgallery","speed":400,"thumbContHeight":80,"thumbWidth":80,"thumbnail":true},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"}};</script><script type="text/javascript" src="/js/theme.min.js"></script><script type="text/javascript">
            window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
            gtag('config', 'UA-198123152-1', { 'anonymize_ip': true });
        </script><script type="text/javascript" src="https://www.googletagmanager.com/gtag/js?id=UA-198123152-1" async></script></body>
</html>
